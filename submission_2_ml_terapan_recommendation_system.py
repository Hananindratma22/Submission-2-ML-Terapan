# -*- coding: utf-8 -*-
"""Submission 2 ML Terapan_Recommendation System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VYPCZDk1IqiCjJmEn_ADwGCq_QyIJa2D

# Identitas Diri
---

**Nama**: Hanan Naufal Indratma  
**Cohort ID**: MC008D5Y2239  
**Group**: MC-10

# Memuat Dataset

Akan diimpor dataset menggunakan link google drive. Dataset yang digunakan dalam proyek ini adalah [MovieLens Dataset](https://www.kaggle.com/datasets/aigamer/movie-lens-dataset?select=tags.csv), yang disediakan oleh GroupLens Research. Dataset ini berisi data interaksi antara pengguna dan film, termasuk penilaian (rating), tag, metadata film, dan informasi penghubung ke sumber eksternal seperti IMDb dan TMDb dengan jumlah total interaksi (ratings) sebanyak **163,046**.
"""

import pandas as pd

# Import data
url_1 = "https://drive.google.com/uc?export=download&id=12-cJxEDCyhn96J9nCK_EjDubDq9TbC_V"
url_2 = "https://drive.google.com/uc?export=download&id=16FuL4pCA--tKPIqoHNwnNxXiUYK3MRL6"
url_3 = "https://drive.google.com/uc?export=download&id=1Cp3tnzu2AcqLVuBoC2iDN8bxZ60XQRGx"
url_4 = "https://drive.google.com/uc?export=download&id=1stegU390qol6kSA5KsM5cxWEqb6_rzj1"

links = pd.read_csv(url_1)
movies = pd.read_csv(url_2)
ratings = pd.read_csv(url_3)
tags = pd.read_csv(url_4)

links.head()

"""Dataset links memiliki 3 kolom."""

movies.head()

"""Dataset movies memiliki 3 kolom."""

ratings.head()

"""Dataset ratings memiliki 4 kolom."""

tags.head()

"""Dataset tags memiliki 4 kolom.

## Menggabungkan Data

Keempat dataset yang sebelumnya diimpor akan digabungkan sehingga menghasilkan 1 dataframe.
"""

# Menggabungkan links dan movies berdasarkan movieId
links_movies = pd.merge(links, movies, on='movieId', how='left')
links_movies.head()

# Menggabungkan ratings dan tags berdasarkan userId dan movieId
links_movies_ratings = pd.merge(ratings, links_movies, on=['movieId'], how = 'left')
links_movies_ratings.head()

# Menggabungkan links_movies dan ratings_tags berdasarkan movieId
links_movies_ratings_tags = pd.merge(links_movies_ratings, tags, on=['userId','movieId'])
links_movies_ratings_tags.head()

links_movies_ratings_tags.drop(['timestamp_x', 'timestamp_y', 'imdbId', 'tmdbId'], axis=1, inplace=True)
links_movies_ratings_tags.head()

df = links_movies_ratings_tags.copy()

"""Dataset yang telah digabungkan, disalin pada dataframe baru untuk memudahkan analisis.

# Exploratory Data Analysis (EDA)

Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset. EDA bertujuan untuk:

   - Tinjau jenis data di setiap kolom.
   - Cek duplikasi data dan missing value.
   - Tinjau jumlah baris dan kolom dalam dataset.  
   - Banyak nilai unik dari user dan movie.

Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan.
"""

df.info()

"""Berdasarkan pengecekan pada tipe data, diperoleh tipe data userId dan movieId adalah integer, rating adalah float, serta variabel lain memiliki tipe data object."""

df.isna().sum().sum()

"""Tidak ditemukan *missing value* pada data."""

df.duplicated().sum()

"""Tidak ditemukan baris duplikat dalam data rating, sehingga data dapat langsung digunakan untuk training model."""

df.shape

"""Data memiliki sebanyak 3476 baris dan 6 kolom."""

# jumlah unik df['userId']
df['userId'].nunique()

# jumlah unik df['movieId']
df['movieId'].nunique()

"""- User unik: **54 pengguna**
- Film unik: **1464 film**

# Model Development dengan Content Based Filtering

Pendekatan ini merekomendasikan film berdasarkan kemiripan konten film yang telah disukai oleh pengguna. Fitur yang digunakan untuk membandingkan antar film adalah kombinasi antara **genre** dan **tag** yang telah diproses menjadi teks gabungan. Model ini menggunakan metode **TF-IDF Vectorizer** dan **Cosine Similarity** untuk mengukur kesamaan antar film.

## Data Preparation

Pada tahap ini, dilakukan serangkaian proses untuk mempersiapkan data sebelum masuk ke tahap pemodelan.

### Variabel Genre
"""

df

# Replace kolom "(no genres listed)"
df['genres'] = df['genres'].replace('(no genres listed)', None)

"""Mengganti nilai `"(no genres listed)"` dengan `"None"` agar lebih mudah dalam pemrosesan teks."""

df.isnull().sum()

df['genre_list'] = df['genres'].dropna().apply(lambda x: x.split('|'))
df

"""Mengubah nilai dalam kolom `genres` dari string yang dipisahkan oleh simbol `|` menjadi list Python.

### Variabel Tag
"""

df

# Gabungkan tag per kombinasi userId dan movieId
df_tag_agg = df.groupby(['userId', 'movieId', 'title', 'genres'], as_index=False)['tag'].agg(lambda x: ' '.join(x))
df_tag_agg

"""Menggabungkan tag per kombinasi `userId` dan `movieId`."""

# Gabungkan df kolom rating dan genre_list, dengan df_tag_agg
df.drop(['tag'], axis=1, inplace=True)
df = pd.merge(df, df_tag_agg, on=['userId', 'movieId', 'title', 'genres'])
df

"""Menggabungkan df kolom rating dan `genre_list`, dengan `df_tag_agg`"""

df['tag_list'] = df['tag'].dropna().apply(lambda x: x.split())
df

"""Menggabungkan semua tag berdasarkan `movieId` ke dalam satu baris, lalu mengubahnya menjadi format list.

### Mengatasi Missing Value

Setelah proses pembersihan dan penggabungan data, dilakukan pemeriksaan dan penanganan nilai null yang muncul sebagai akibat dari join antar tabel.
"""

# Mengecek missing value pada dataframe all_resto
df.isnull().sum()

df.dropna(inplace=True)

"""### Gabung List Genre & Tag

Kolom `genres` dan `tags` digabungkan ke dalam satu kolom baru bernama `text`, yang berisi deskripsi gabungan konten film.
"""

# Gabungkan genre dan tag ke satu string per baris
df['text'] = df.apply(lambda row: ' '.join(row['genre_list'] + row['tag_list']), axis=1)
df.drop(['genres', 'tag', 'genre_list', 'tag_list'], axis=1, inplace=True)

df.head()

"""### Mengatasi Duplikasi

Dilakukan pemeriksaan terhadap duplikasi data untuk memastikan hanya satu representasi konten per film.
"""

df.duplicated().sum()

df.drop_duplicates(inplace=True)

"""### Lower Case

Melakukan transformasi lowercasing terhadap kolom `title` dan `text` untuk standarisasi dan mengurangi redundansi kata.
"""

# Membuat data teks menjadi huruf kecil
df['title'] = df['title'].fillna('').str.lower()
df['text'] = df['text'].fillna('').str.lower()
df.head()

# Gabungkan semua text per movieId (dan title)
df_content = df.groupby(['movieId', 'title'])['text'].apply(lambda texts: ' '.join(set(texts))).reset_index()
df_content.head()

"""Menggabungkan semua text per `movieId` dan `title`"""

df_content.shape

"""### TF-IDF Vectorizer

Menerapkan `TfidfVectorizer` dari scikit-learn untuk mentransformasikan kolom `text` menjadi representasi vektor numerik.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# TF-IDF dari genre+tag
tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df_content['text'])

"""### Cosine Similarity

Menghitung kemiripan antar film menggunakan cosine similarity pada vektor hasil TF-IDF.
"""

# Cosine similarity antar film
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=df_content['title'], columns=df_content['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap title
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Pada dataframe tersebut terlihat similarity masing-masing film dengan film lainnya berdasarkan nilai cosine similarity yang telah dihitung.

## Mendapatkan Rekomendasi

Pada tahap ini, sistem rekomendasi dibangun untuk menyelesaikan permasalahan yang telah diidentifikasi sebelumnya, yaitu memberikan rekomendasi film yang relevan kepada pengguna berdasarkan preferensi mereka.
"""

def movie_recommendations(title, similarity_data=cosine_sim_df, items=df_content[['title', 'text']], k=5):
    """
    Rekomendasi film berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_resto : tipe data string (str)
                Nama Restoran (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan title sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Fungsi `movie_recommendations` dirancang untuk memberikan rekomendasi film berdasarkan kemiripan konten menggunakan pendekatan content-based filtering. Fungsi ini menerima empat parameter: `title` sebagai judul film yang menjadi acuan, `similarity_data` berupa DataFrame simetri yang berisi skor kemiripan antar film (biasanya hasil perhitungan cosine similarity), `items` yang berisi informasi metadata film seperti judul dan fitur teks, serta `k` sebagai jumlah rekomendasi yang ingin ditampilkan. Prosesnya dimulai dengan mengambil skor kemiripan antara film acuan dengan seluruh film lain dalam bentuk array, lalu menggunakan `argpartition` untuk mengekstrak indeks dengan nilai kemiripan tertinggi. Dari indeks tersebut, diambil `k+1` film terdekat (karena film acuan juga akan termasuk di dalamnya), kemudian nama film acuan dihapus dari hasil untuk menghindari rekomendasi terhadap dirinya sendiri. Hasil akhirnya adalah DataFrame berisi film-film yang paling mirip, digabungkan dengan metadata dari `items`, dan ditampilkan sebanyak `k` film.

"""

df_content[df_content.title.eq('jumanji (1995)')]

"""Dicari top 5 rekomendasi film yang mirip dengan Jumanji."""

# Mendapatkan rekomendasi film yang mirip dengan Jumanji
movie_recommendations('jumanji (1995)')

"""**Top 5 Movie Recommendation yang mirip dengan Jumanji:**
1. *big (1988)*
2. *harry potter and the sorcerer's stone (2001)*
3. *tomb raider (2018)*
4. *toy story (1995)*
5. *it takes two (1995)*

# Model Development dengan Collaborative Filtering

Pendekatan ini merekomendasikan film dengan mempelajari pola interaksi antar pengguna dan item (film). Model ini dibangun dengan pendekatan **user-item matrix** yang diencoding dan dilatih menggunakan pembelajaran terstruktur (matrix factorization).
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Model, layers, regularizers, optimizers, losses, metrics
from pathlib import Path
import matplotlib.pyplot as plt

df

df_collaborative = df.drop(['title', 'text'], axis=1)
df_collaborative

"""Membuat dataframe baru `df_collaborative` yang akan digunakan dalam development model dengan collaborative filtering.

## Data Preparation

Pada tahap ini, dilakukan serangkaian proses untuk mempersiapkan data sebelum masuk ke tahap pemodelan.

### List dan Encoding Variabel
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df_collaborative['userId'].unique().tolist()
print('list userId: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userid : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userid: ', user_encoded_to_user)

"""Membuat userID menjadi list tanpa nilai yang sama serta melakukan encoding pada id user."""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df_collaborative['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""Membuat movieId menjadi list tanpa nilai yang sama serta melakukan encoding pada id movie."""

# Mapping userID ke dataframe user
df_collaborative['user'] = df_collaborative['userId'].map(user_to_user_encoded)

# Mapping movieID ke dataframe movie
df_collaborative['movie'] = df_collaborative['movieId'].map(movie_to_movie_encoded)

"""Melakukan mapping userID dan movieID ke dataframe user dan movie."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah resto
num_movie = len(movie_to_movie_encoded)
print(num_movie)

# Mengubah rating menjadi nilai float
df_collaborative['rating'] = df_collaborative['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df_collaborative['rating'])

# Nilai maksimal rating
max_rating = max(df_collaborative['rating'])

print('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Mendapatkan beberapa informasi baru seperti jumlah user, jumlah resto, minimal rating, dan maksimal rating.

### Membagi Data untuk Training dan Validasi

Data dibagi ke dalam `x_train`, `x_val`, `y_train`, dan `y_val` menggunakan teknik split, dengan proporsi training dan validation.
"""

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df_collaborative[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df_collaborative['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df_collaborative.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""### Penyesuaian Tipe Data

Mengonversi `x_train` dan `x_val` ke tipe `int32` dan label `y_train` serta `y_val` ke `float32`. Hal ini dilakukan karena TensorFlow mengharuskan input dan output memiliki tipe data numerik spesifik agar kompatibel dengan arsitektur model.
"""

# Cek tipe data yang sebenarnya
print("=== DEBUGGING DATA ===")
print(f"Type x_train: {type(x_train)}")
print(f"Type y_train: {type(y_train)}")
print(f"Type x_val: {type(x_val)}")
print(f"Type y_val: {type(y_val)}")

if hasattr(x_train, 'shape'):
    print(f"Shape x_train: {x_train.shape}")
if hasattr(y_train, 'shape'):
    print(f"Shape y_train: {y_train.shape}")

print(f"Sample x_train:\n{x_train.head() if isinstance(x_train, pd.DataFrame) else x_train[:3]}")
print(f"Sample y_train:\n{y_train.head() if isinstance(y_train, pd.DataFrame) else y_train[:3]}")

# Konversi Data dari Dataframe ke Numpy Array
def convert_to_numpy(data):
    """Konversi DataFrame atau Series ke numpy array"""
    if isinstance(data, pd.DataFrame):
        return data.values.astype(np.int32)
    elif isinstance(data, pd.Series):
        return data.values.astype(np.float32)
    elif isinstance(data, np.ndarray):
        return data
    else:
        return np.array(data)

# Konversi semua data
print("\n=== KONVERSI DATA ===")
x_train_converted = convert_to_numpy(x_train)
y_train_converted = convert_to_numpy(y_train)
x_val_converted = convert_to_numpy(x_val)
y_val_converted = convert_to_numpy(y_val)

# Pastikan dtype yang tepat
x_train_converted = x_train_converted.astype(np.int32)
y_train_converted = y_train_converted.astype(np.float32)
x_val_converted = x_val_converted.astype(np.int32)
y_val_converted = y_val_converted.astype(np.float32)

print(f"Converted x_train - Type: {type(x_train_converted)}, Shape: {x_train_converted.shape}, Dtype: {x_train_converted.dtype}")
print(f"Converted y_train - Type: {type(y_train_converted)}, Shape: {y_train_converted.shape}, Dtype: {y_train_converted.dtype}")
print(f"Sample x_train_converted:\n{x_train_converted[:3]}")
print(f"Sample y_train_converted:\n{y_train_converted[:3]}")

"""## Training Model

Pada tahap ini, sistem rekomendasi dibangun untuk menyelesaikan permasalahan yang telah diidentifikasi sebelumnya, yaitu memberikan rekomendasi film yang relevan kepada pengguna berdasarkan preferensi mereka.
"""

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Embedding, Flatten
import numpy as np
import pandas as pd

class RecommenderNet(Model):
    def __init__(self, num_users, num_movie, embedding_size=50, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)

        # Pastikan input_dim adalah integer, bukan DataFrame atau Series
        self.num_users = int(num_users)
        self.num_movie = int(num_movie)
        self.embedding_size = embedding_size

        self.user_embedding = Embedding(
            input_dim=self.num_users,
            output_dim=embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=None,
            name="user_embedding"
        )
        self.user_bias = Embedding(
            input_dim=self.num_users,
            output_dim=1,
            name="user_bias"
        )

        self.movie_embedding = Embedding(
            input_dim=self.num_movie,
            output_dim=embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=None,
            name="movie_embedding"
        )
        self.movie_bias = Embedding(
            input_dim=self.num_movie,
            output_dim=1,
            name="movie_bias"
        )

    def build(self, input_shape):
        """Implementasi build method yang proper"""
        super(RecommenderNet, self).build(input_shape)

    def call(self, inputs):
        # Pastikan input adalah tensor dengan dtype int32
        inputs = tf.convert_to_tensor(inputs, dtype=tf.int32)

        # Extract user dan movie IDs
        user_id = inputs[:, 0]
        movie_id = inputs[:, 1]

        # Reshape untuk memastikan dimensi yang tepat
        user_id = tf.reshape(user_id, [-1])
        movie_id = tf.reshape(movie_id, [-1])

        # Embedding lookup
        user_vector = self.user_embedding(user_id)
        user_bias = self.user_bias(user_id)
        user_bias = tf.reshape(user_bias, [-1, 1])

        movie_vector = self.movie_embedding(movie_id)
        movie_bias = self.movie_bias(movie_id)
        movie_bias = tf.reshape(movie_bias, [-1, 1])

        # Compute dot product
        dot_user_movie = tf.reduce_sum(user_vector * movie_vector, axis=1, keepdims=True)

        # Final prediction
        x = dot_user_movie + user_bias + movie_bias

        return tf.nn.sigmoid(x)

"""Model `RecommenderNet` adalah implementasi neural collaborative filtering yang menggunakan arsitektur embedding untuk merepresentasikan user dan movie ke dalam vektor berdimensi tetap. Di dalam konstruktor, model menginisialisasi embedding untuk user dan movie dengan ukuran `embedding_size`, serta bias masing-masing. Pada metode `call`, model menerima input pasangan `(user_id, movie_id)`, lalu mencari representasi vektor masing-masing melalui embedding lookup, menghitung dot product antar user dan movie vector sebagai representasi interaksi, dan menambahkan bias user dan movie untuk menghasilkan prediksi rating akhir. Aktivasi sigmoid digunakan di akhir untuk memastikan output berada pada skala 0 hingga 1, cocok untuk prediksi rating terskalakan atau preferensi biner.

"""

# Inisialisasi Model
print("\n=== INISIALISASI MODEL ===")

# PENTING: Pastikan num_users dan num_movie adalah integer murni
# Bukan pandas Series atau DataFrame
print(f"num_users type: {type(num_users)}, value: {num_users}")
print(f"num_movie type: {type(num_movie)}, value: {num_movie}")

# Konversi ke integer jika masih pandas object
if hasattr(num_users, 'iloc') or isinstance(num_users, (pd.Series, pd.DataFrame)):
    num_users = int(num_users.iloc[0] if hasattr(num_users, 'iloc') else num_users)
if hasattr(num_movie, 'iloc') or isinstance(num_movie, (pd.Series, pd.DataFrame)):
    num_movie = int(num_movie.iloc[0] if hasattr(num_movie, 'iloc') else num_movie)

#print(f"After conversion - num_users: {num_users}, num_movie: {num_movie}")

# Buat model baru
model = RecommenderNet(num_users=num_users, num_movie=num_movie, embedding_size=50)

# Compile model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

print("Model berhasil dibuat!")

"""Kode ini bertujuan untuk menginisialisasi dan meng-compile model `RecommenderNet`. Sebelum model dibuat, dilakukan pengecekan dan konversi tipe data untuk memastikan bahwa `num_users` dan `num_movie` bertipe integer murni, bukan objek pandas seperti Series atau DataFrame, agar tidak terjadi error saat inisialisasi embedding layer. Setelah itu, model dibuat dengan parameter jumlah user, jumlah movie, dan ukuran embedding sebesar 50. Model kemudian dikompilasi menggunakan fungsi loss `BinaryCrossentropy`—yang sesuai untuk kasus klasifikasi biner atau preferensi like/dislike—dengan optimizer `Adam`, serta menggunakan metrik `RootMeanSquaredError` (RMSE) untuk mengevaluasi akurasi prediksi terhadap rating aktual. Langkah ini memastikan model siap untuk dilatih dengan data interaksi user-movie.

"""

# Model Training
print("\n=== TRAINING MODEL ===")
try:
    history = model.fit(
        x=x_train_converted,  # Gunakan data yang sudah dikonversi
        y=y_train_converted,  # Gunakan data yang sudah dikonversi
        batch_size=8,
        epochs=100,
        validation_data=(x_val_converted, y_val_converted),  # Data validasi yang sudah dikonversi
        verbose=1
    )
    print("Training berhasil!")
except Exception as e:
    print(f"Error saat training: {e}")
    import traceback
    traceback.print_exc()

"""Model dilatih menggunakan data pelatihan (`x_train_converted` dan `y_train_converted`) yang telah dikonversi sebelumnya, dengan ukuran batch sebesar 8 dan selama 100 epoch. Selain itu, disediakan data validasi (`x_val_converted` dan `y_val_converted`) untuk mengevaluasi kinerja model selama proses pelatihan. Proses ini dijalankan dalam blok try-except untuk menangani potensi kesalahan. Jika proses pelatihan berhasil, sistem akan mencetak "Training berhasil!", sedangkan jika terjadi kesalahan, pesan error akan ditampilkan lengkap dengan jejak traceback untuk membantu proses debugging.

## Visualisasi Metrik
"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model_metrics')
plt.ylabel('mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

"""Grafik menunjukkan *loss* dan *val_loss* serta RMSE pada training dan validasi. RMSE training menurun hingga mendekati 0.49, sementara RMSE validasi stabil di sekitar 0.655."""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

"""Grafik RMSE training mencapai sekitar 0.02 dan RMSE validasi turun ke kisaran 0.285. Ini menunjukkan perbaikan signifikan dalam generalisasi dan akurasi prediksi model.

## Mendapatkan Rekomendasi
"""

movie_df = df_content

# Mengambil sample user
user_id = df_collaborative.userId.sample(1).iloc[0]
movie_watched_by_user = df_collaborative[df_collaborative.userId == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
movie_not_watched = movie_df[~movie_df['movieId'].isin(movie_watched_by_user.movieId.values)]['movieId']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)
user_movie_array = tf.convert_to_tensor(user_movie_array, dtype=tf.int32)

"""Kode ini bertujuan untuk menyiapkan data input bagi model dalam memberikan rekomendasi film kepada seorang pengguna. Pertama, seluruh data film disalin ke dalam variabel `movie_df`. Kemudian, dipilih secara acak satu `userId` dari data collaborative filtering (`df_collaborative`), dan diambil daftar film yang sudah ditonton oleh pengguna tersebut. Selanjutnya, dengan menggunakan operator bitwise NOT (`~`) dan fungsi `isin`, disaring daftar film yang *belum* ditonton oleh pengguna. Daftar ini kemudian difilter agar hanya mencakup film yang memiliki representasi dalam kamus `movie_to_movie_encoded`. Setiap ID film dalam daftar tersebut kemudian dikonversi ke bentuk numerik dan dikombinasikan dengan ID pengguna yang juga telah dienkode. Akhirnya, seluruh pasangan pengguna–film yang akan diprediksi dikonversi menjadi tensor (`tf.convert_to_tensor`) dengan tipe data `int32`, yang siap diberikan sebagai input ke model untuk melakukan prediksi rekomendasi.

"""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-5:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['movieId'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.text)

print('----' * 8)
print('Top 5 movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['movieId'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.text)

"""**Top Movie dengan rating tinggi dari user dengan id 474:**
1. *sense and sensibility (1995)*
2. *shawshank redemption, the (1994)*
3. *fugitive, the (1993)*
4. *memento (2000)*
5. *about a boy (2002)*


**Top 5 Movie Recommendation yang cocok dengan user dengan id 474:**
1. *jezebel (1938)*
2. *gone baby gone (2007)*
3. *the dark knight (2008)*
4. *the hateful eight (2015)*
5. *who killed chea vichea? (2010)*
"""